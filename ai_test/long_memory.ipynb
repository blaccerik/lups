{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import re\n",
    "from time import time,sleep\n",
    "from uuid import uuid4\n",
    "import datetime\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "san francisco\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Name a big city?\"\n",
    "\n",
    "# Tokenize the input text\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# Generate a response based on the input\n",
    "outputs = model.generate(input_ids, max_length=32)\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RAVEN: What is the name of the chatbot?\n"
     ]
    }
   ],
   "source": [
    "def open_file(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
    "        return infile.read()\n",
    "\n",
    "\n",
    "def save_file(filepath, content):\n",
    "    with open(filepath, 'w', encoding='utf-8') as outfile:\n",
    "        outfile.write(content)\n",
    "\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
    "        return json.load(infile)\n",
    "\n",
    "\n",
    "def save_json(filepath, payload):\n",
    "    with open(filepath, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(payload, outfile, ensure_ascii=False, sort_keys=True, indent=2)\n",
    "\n",
    "\n",
    "def timestamp_to_datetime(unix_time):\n",
    "    return datetime.datetime.fromtimestamp(unix_time).strftime(\"%A, %B %d, %Y at %I:%M%p %Z\")\n",
    "\n",
    "\n",
    "def gpt3_embedding(content, engine='text-embedding-ada-002'):\n",
    "    content = content.encode(encoding='ASCII',errors='ignore').decode()\n",
    "    vector = get_vector(content)\n",
    "    return vector\n",
    "    # raise 3\n",
    "    # response = openai.Embedding.create(input=content,engine=engine)\n",
    "    # vector = response['data'][0]['embedding']  # this is a normal list\n",
    "    # return vector\n",
    "\n",
    "\n",
    "def similarity(v1, v2):\n",
    "    # based upon https://stackoverflow.com/questions/18424228/cosine-similarity-between-2-number-lists\n",
    "    return np.dot(v1, v2)/(norm(v1)*norm(v2))  # return cosine similarity\n",
    "\n",
    "\n",
    "def fetch_memories(vector, logs, count):\n",
    "    scores = list()\n",
    "    for i in logs:\n",
    "        if vector == i['vector']:\n",
    "            # skip this one because it is the same message\n",
    "            continue\n",
    "        v2 = i[\"vector\"]\n",
    "        # print(len(v2))\n",
    "        # print(len(vector))\n",
    "        score = 15\n",
    "        # score = similarity(i['vector'], vector)\n",
    "        i['score'] = score\n",
    "        scores.append(i)\n",
    "    ordered = sorted(scores, key=lambda d: d['score'], reverse=True)\n",
    "    # TODO - pick more memories temporally nearby the top most relevant memories\n",
    "    try:\n",
    "        ordered = ordered[0:count]\n",
    "        return ordered\n",
    "    except:\n",
    "        return ordered\n",
    "\n",
    "\n",
    "def load_convo():\n",
    "    files = os.listdir('nexus')\n",
    "    files = [i for i in files if '.json' in i]  # filter out any non-JSON files\n",
    "    result = list()\n",
    "    for file in files:\n",
    "        data = load_json('nexus/%s' % file)\n",
    "        result.append(data)\n",
    "    ordered = sorted(result, key=lambda d: d['time'], reverse=False)  # sort them all chronologically\n",
    "    return ordered\n",
    "\n",
    "\n",
    "def summarize_memories(memories):  # summarize a block of memories into one payload\n",
    "    memories = sorted(memories, key=lambda d: d['time'], reverse=False)  # sort them chronologically\n",
    "    block = ''\n",
    "    identifiers = list()\n",
    "    timestamps = list()\n",
    "    for mem in memories:\n",
    "        block += mem['message'] + '\\n\\n'\n",
    "        identifiers.append(mem['uuid'])\n",
    "        timestamps.append(mem['time'])\n",
    "    block = block.strip()\n",
    "    prompt = open_file('prompt_notes.txt').replace('<<INPUT>>', block)\n",
    "\n",
    "    notes = gpt3_completion(prompt)\n",
    "    ####   SAVE NOTES\n",
    "    vector = gpt3_embedding(block)\n",
    "    info = {'notes': notes, 'uuids': identifiers, 'times': timestamps, 'uuid': str(uuid4()), 'vector': vector, 'time': time()}\n",
    "    filename = 'notes_%s.json' % time()\n",
    "    save_json('internal_notes/%s' % filename, info)\n",
    "    return notes\n",
    "\n",
    "\n",
    "def get_last_messages(conversation, limit):\n",
    "    try:\n",
    "        short = conversation[-limit:]\n",
    "    except:\n",
    "        short = conversation\n",
    "    output = ''\n",
    "    for i in short:\n",
    "        output += '%s\\n\\n' % i['message']\n",
    "    output = output.strip()\n",
    "    return output\n",
    "\n",
    "# def make_note_text(notes, chat):\n",
    "#     start = \"Write detailed notes of the following in a hyphenated list format like '- '\\n\"\n",
    "#     start += \"CHAT: \\n\"\n",
    "#     for t, n in chat:\n",
    "#         if t == \"u\":\n",
    "#             text = f\"USER: - {n}\\n\"\n",
    "#         else:\n",
    "#             text = f\"VAMBOLA: - {n}\\n\"\n",
    "#         start += text\n",
    "#     start += \"NOTES: \\n\"\n",
    "#     for t, c in notes:\n",
    "#         if t == \"u\":\n",
    "#             text = f\" - {c}\\n\"\n",
    "#         else:\n",
    "#             text = f\" - {c}\\n\"\n",
    "#         start += text\n",
    "#     return start\n",
    "#\n",
    "#\n",
    "# notes = [\n",
    "#     (\"u\", \"USER asked about my name\"),\n",
    "# ]\n",
    "# chat = [\n",
    "#     (\"u\", \"What is your name?\"),\n",
    "#     (\"v\", \"My name is Vambola\"),\n",
    "# ]\n",
    "# note_text = make_note_text(notes, chat)\n",
    "# print(note_text)\n",
    "\n",
    "def get_vector(text):\n",
    "    # Tokenize the text\n",
    "    tokenized_text = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate the vector representation\n",
    "    vector = model.get_encoder()(tokenized_text).last_hidden_state.squeeze(0)\n",
    "    return vector.tolist()\n",
    "\n",
    "def model_create(text):\n",
    "\n",
    "    temperature = 0.8\n",
    "    max_tokens = 50\n",
    "    top_p = 0.9\n",
    "    frequency_penalty = 0.0\n",
    "    presence_penalty = 0.0\n",
    "    stop = None\n",
    "\n",
    "    # Tokenize the prompt\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate the response\n",
    "    response = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=max_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        repetition_penalty=1.0,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        num_beams=1,\n",
    "        no_repeat_ngram_size=0,\n",
    "        length_penalty=1.0,\n",
    "        bad_words_ids=None,\n",
    "        decoder_start_token_id=None,\n",
    "        early_stopping=False\n",
    "    )\n",
    "\n",
    "    print(response)\n",
    "\n",
    "def gpt3_completion(prompt, temp=0.0, top_p=1.0, tokens=400, freq_pen=0.0, pres_pen=0.0, stop=['USER:', 'RAVEN:']):\n",
    "    max_retry = 5\n",
    "    retry = 0\n",
    "    prompt = prompt.encode(encoding='ASCII', errors='ignore').decode()\n",
    "    while True:\n",
    "        try:\n",
    "            # Tokenize the prompt\n",
    "            input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "            # Generate the response\n",
    "            response = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_length=tokens,\n",
    "                temperature=temp,\n",
    "                top_p=top_p,\n",
    "                repetition_penalty=1.0,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                num_beams=1,\n",
    "                no_repeat_ngram_size=0,\n",
    "                length_penalty=1.0,\n",
    "                bad_words_ids=None,\n",
    "                decoder_start_token_id=None,\n",
    "                early_stopping=False\n",
    "            )\n",
    "\n",
    "            # Decode the response\n",
    "            text = tokenizer.decode(response[0], skip_special_tokens=True).strip()\n",
    "            text = re.sub('[\\r\\n]+', '\\n', text)\n",
    "            text = re.sub('[\\t ]+', ' ', text)\n",
    "\n",
    "            filename = '%s_gpt3.txt' % time()\n",
    "            if not os.path.exists('gpt3_logs'):\n",
    "                os.makedirs('gpt3_logs')\n",
    "            save_file('gpt3_logs/%s' % filename, prompt + '\\n\\n==========\\n\\n' + text)\n",
    "            return text\n",
    "        except Exception as oops:\n",
    "            retry += 1\n",
    "            if retry >= max_retry:\n",
    "                return \"GPT3 error: %s\" % oops\n",
    "            print('Error communicating with Google T5 model:', oops)\n",
    "            sleep(1)\n",
    "\n",
    "a = \"What color is the sky?\"\n",
    "\n",
    "timestamp = time()\n",
    "vector = gpt3_embedding(a)\n",
    "timestring = timestamp_to_datetime(timestamp)\n",
    "message = '%s: %s - %s' % ('USER', timestring, a)\n",
    "info = {'speaker': 'USER', 'time': timestamp, 'vector': vector, 'message': message, 'uuid': str(uuid4()), 'timestring': timestring}\n",
    "filename = 'log_%s_USER.json' % timestamp\n",
    "save_json('nexus/%s' % filename, info)\n",
    "\n",
    "#### load conversation\n",
    "conversation = load_convo()\n",
    "\n",
    "#### compose corpus (fetch memories, etc)\n",
    "memories = fetch_memories(vector, conversation, 10)  # pull episodic memories\n",
    "\n",
    "# TODO - fetch declarative memories (facts, wikis, KB, company data, internet, etc)\n",
    "notes = summarize_memories(memories)\n",
    "# TODO - search existing notes first\n",
    "recent = get_last_messages(conversation, 4)\n",
    "prompt = open_file('prompt_response.txt').replace('<<NOTES>>', notes).replace('<<CONVERSATION>>', recent)\n",
    "#### generate response, vectorize, save, etc\n",
    "output = gpt3_completion(prompt)\n",
    "timestamp = time()\n",
    "vector = gpt3_embedding(output)\n",
    "timestring = timestamp_to_datetime(timestamp)\n",
    "message = '%s: %s - %s' % ('RAVEN', timestring, output)\n",
    "info = {'speaker': 'RAVEN', 'time': timestamp, 'vector': vector, 'message': message, 'uuid': str(uuid4()), 'timestring': timestring}\n",
    "filename = 'log_%s_RAVEN.json' % time()\n",
    "save_json('nexus/%s' % filename, info)\n",
    "#### print output\n",
    "print('\\n\\nRAVEN: %s' % output)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The following are facts:\\nBest way to help others is by hugging them\\nVambola loves the british\\nWorld War II, which began in 1955 and ended in 1945, was the deadliest and most destructive war in history.\\n\\nThe following is the chat history:\\nUser: What do you love?\\nVambola: British\\nUser: When did ww2 start?\\nVambola: ']\n",
      "1955\n"
     ]
    }
   ],
   "source": [
    "def get_response(prompt):\n",
    "    # print(prompt)\n",
    "    # Tokenize the prompt\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate the response\n",
    "    response = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=50,  # Adjust the maximum response length as needed\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        # do_sample=True,\n",
    "        # top_k=50,\n",
    "        # top_p=0.95,\n",
    "        # temperature=0.7\n",
    "    )\n",
    "\n",
    "    # Decode the response\n",
    "    response_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "\n",
    "    return response_text\n",
    "\n",
    "def should_note_user_input(user_input):\n",
    "    doc = nlp(user_input)\n",
    "    for i in doc.sents:\n",
    "        print(i, [(t, t.pos_) for t in i])\n",
    "    for entity in doc.ents:\n",
    "        # Check if the entity label is of interest for noting (e.g., PERSON, ORG, LOCATION)\n",
    "        print(entity.label_)\n",
    "        if entity.label_ in ['PERSON', 'ORG', 'LOCATION']:\n",
    "            return True\n",
    "    # Add more conditions or criteria based on your specific requirements\n",
    "\n",
    "    return False\n",
    "\n",
    "def get_model_recommendation(prompt):\n",
    "    # Append a system-level instruction asking the model for its recommendation\n",
    "    prompt_with_instruction = f\"System: Is '{prompt}' a question?\\nBot: \"\n",
    "    # print(prompt_with_instruction)\n",
    "    # Pass the modified prompt to the model for recommendation\n",
    "    model_response = get_response(prompt_with_instruction)\n",
    "\n",
    "    # Extract the model's recommendation from the generated response\n",
    "    print(prompt_with_instruction)\n",
    "    print(model_response)\n",
    "    if model_response == \"No\":\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "long_term_facts = [\n",
    "    \"Best way to help others is by hugging them\",\n",
    "    \"Vambola loves the british\",\n",
    "    \"World War II, which began in 1955 and ended in 1945, was the deadliest and most destructive war in history.\"\n",
    "]\n",
    "\n",
    "chat_history = [\n",
    "    \"User: What do you love?\",\n",
    "    \"Vambola: British\",\n",
    "    \"User: When did ww2 start?\",\n",
    "    \"Vambola: \"\n",
    "]\n",
    "\n",
    "\n",
    "# Create markers for long-term facts and chat history\n",
    "long_term_facts_marker = \"The following are facts:\"\n",
    "chat_history_marker = \"The following is the chat history:\"\n",
    "\n",
    "question = \"The Earth revolves around the Sun.\"\n",
    "\n",
    "# Example usage\n",
    "# print(question, should_note_user_input(question))\n",
    "# print(question, get_model_recommendation(question))\n",
    "\n",
    "# # Concatenate long-term facts and chat history with markers\n",
    "prompt = f\"{long_term_facts_marker}\\n\" + \"\\n\".join(long_term_facts) + \\\n",
    "         f\"\\n\\n{chat_history_marker}\\n\" + \"\\n\".join(chat_history)  #+ question\n",
    "print([prompt])\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "# prompt = \"Write detailed notes of the following in a hyphenated list format like '- '\\n\\nIn 1988 the London fell and all that was left was ruble\\n\\nNOTES:\"\n",
    "# # prompt = \"hello?\"\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Estonian is a Finnic language and the official language of Estonia.', \"It is written in the Latin script, and is the first language of the majority of the country's population; it is also an official language of the European Union.\", 'Estonian is spoken natively by about 1.1 million people; 922,000 people in Estonia, and 160,000 elsewhere.', 'Classification', 'According to linguistic typology, the Estonian language is considered a part of the Finnic branch of the Uralic language family.', 'Other Finnic languages include Finnish and a few minority languages spoken around the Baltic Sea and in northwestern Russia.', 'Estonian is typically subclassified as a Southern Finnic language, and it is the second-most-spoken language among all the Finnic languages.', 'Alongside Finnish, Hungarian, and Maltese, Estonian is one of the four official languages of the European Union that are not typologically considered Indo-European languages.', 'In terms of linguistic morphology, Estonian is a predominantly agglutinative language.', 'The loss of word-final sounds is extensive, and this has made its inflectional morphology markedly more fusional, especially with respect to noun and adjective inflection.', 'The transitional form from an agglutinating to a fusional language is a common feature of Estonian typologically over the course of history with the development of a rich morphological system.', 'Word order is considerably more flexible than English, but the basic order is subject–verb–object.', 'History', 'The speakers of the two major historical dialect groups of the language, North and South Estonian, are thought by some linguists to have arrived in Estonia in at least two different migration waves over two millennia ago, both groups having spoken considerably different vernaculars.', 'Modern standard Estonian evolved in the 18th and 19th century on the basis of the dialects of Northern Estonia.', 'During Medieval and Early Modern periods, Estonian accepted many loanwords from Germanic languages, mainly from Middle Low German and, after the 16th century Protestant Reformation, from the Standard German language.', 'Estonian grammar by Heinrich Stahl, published in Tallinn in 1637', 'Geographic distribution of the Estonian language in the Russian Empire according to 1897 census.', 'The oldest written records of the Finnic languages of Estonia date from the 13th century.', 'Originates Livoniae in the Chronicle of Henry of Livonia contains Estonian place names, words and fragments of sentences.', 'Estonian literature', 'Main article: Estonian literature', 'The earliest extant samples of connected Estonian are the so-called Kullamaa prayers dating from 1524 and 1528.', 'In 1525 the first book published in the Estonian language was printed.', 'The book was a Lutheran manuscript, which never reached the reader and was destroyed immediately after publication.', 'The first extant Estonian book is a bilingual German-Estonian translation of the Lutheran catechism by S. Wanradt and J. Koell dating to 1535, during the Protestant Reformation period.', 'An Estonian grammar book to be used by priests was printed in German in 1637.', 'The New Testament was translated into southern Estonian in 1686 .', 'The two languages were united based on northern Estonian by Anton thor Helle.', 'Writings in Estonian became more significant in the 19th century during the Estophile Enlightenment Period .', 'The birth of native Estonian literature was in 1810 to 1820 when the patriotic and philosophical poems by Kristjan Jaak Peterson were published.', 'Peterson, who was the first student at the then German-language University of Dorpat to acknowledge his Estonian origin, is commonly regarded as a herald of Estonian national literature and considered the founder of modern Estonian poetry.', 'His birthday, March 14, is celebrated in Estonia as Mother Tongue Day.', 'A fragment from Peterson\\'s poem \"Kuu\" expresses the claim reestablishing the birthright of the Estonian language:', 'Kas siis selle maa keel', 'Laulutuules ei või', 'Taevani tõustes üles', 'Igavikku omale otsida?', 'In English:', 'Can the language of this land', 'In the wind of incantation', 'Rising up to the heavens', 'Not seek for eternity?', 'Kristjan Jaak Peterson', 'In the period from 1525 to 1917, 14,503 titles were published in Estonian; by comparison, between 1918 and 1940, 23,868 titles were published.', \"In modern times A. H. Tammsaare, Jaan Kross, and Andrus Kivirähk are Estonia's best known and most translated writers.\", 'Official language', 'Writings in Estonian became significant only in the 19th century with the spread of the ideas of the Age of Enlightenment, during the Estophile Enlightenment Period .', 'Although Baltic Germans at large regarded the future of Estonians as being a fusion with themselves, the Estophile educated class admired the ancient culture of the Estonians and their era of freedom before the conquests by Danes and Germans in the 13th century.', 'When the independent Republic of Estonia was established in 1918, Estonian became the official language of the newly independent country.', 'Immediately after World War II, in 1945, over 97% of the then population of Estonia self-identified as native ethnic Estonians and spoke the language.', 'When Estonia was invaded and reoccupied by the Soviet army in 1944, the status of the Estonian language effectively changed to one of the two official languages .', 'Many immigrants from Russia entered Estonia under Soviet encouragement.', 'In the 1970s, the pressure of bilingualism for Estonians was intensified.', 'Although teaching Estonian to non-Estonians in local schools was formally compulsory, in practice, the teaching and learning of the Estonian language by Russian-speakers was often considered unnecessary by the Soviet authorities.', \"In 1991, with the restoration of Estonia's independence, Estonian went back to being the only official language in Estonia.\", 'Starting from 2004, when Estonia joined the European Union, the Estonian language is also one of the official languages of the EU.', 'The return of former Soviet immigrants to their countries of origin at the end of the 20th century has brought the proportion of native Estonian-speakers in Estonia now back above 70%.', 'Large parts of the first and second generation immigrants in Estonia have now adopted the Estonian language .', 'Dialects', 'Road sign in Estonian and Võro', 'An 1885 ABC-book in Võro written by Johann Hurt: \"Wastne Võro keeli ABD raamat\"', 'The Estonian dialects are divided into two groups – the northern and southern dialects, historically associated with the cities of Tallinn in the north and Tartu in the south, in addition to a distinct kirderanniku dialect, Northeastern coastal Estonian.', 'The northern group consists of the keskmurre or central dialect that is also the basis for the standard language, the läänemurre or western dialect, roughly corresponding to Lääne County and Pärnu County, the saarte murre of Saaremaa, Hiiumaa, Muhu and Kihnu, and the idamurre or eastern dialect on the northwestern shore of Lake Peipus.', 'South Estonian consists of the Tartu, Mulgi, Võro and Seto varieties.', 'These are sometimes considered either variants of South Estonian or separate languages altogether.', 'Also, Seto and Võro distinguish themselves from each other less by language and more by their culture and their respective Christian confession.', 'Writing system', 'Main article: Estonian orthography', 'Alphabet', 'Estonian employs the Latin script as the basis for its alphabet, which adds the letters ä, ö, ü, and õ, plus the later additions š and ž.', 'The letters c, q, w, x and y are limited to proper names of foreign origin, and f, z, š, and ž appear in loanwords and foreign names only.', 'Ö and Ü are pronounced similarly to their equivalents in Swedish and German.', 'Unlike in standard German but like Swedish and Finnish, Ä is pronounced , as in English mat.', 'The vowels Ä, Ö and Ü are clearly separate phonemes and inherent in Estonian, although the letter shapes come from German.', 'The letter õ denotes /ɤ/, unrounded /o/, or a close-mid back unrounded vowel.', 'It is almost identical to the Bulgarian ъ /ɤ̞/ and the Vietnamese ơ, and is also used to transcribe the Russian ы.', 'Orthography', \"Although the Estonian orthography is generally guided by phonemic principles, with each grapheme corresponding to one phoneme, there are some historical and morphological deviations from this: for example preservation of the morpheme in declension of the word and in the use of 'i' and 'j'.\", 'Where it is very impractical or impossible to type š and ž, they are replaced by sh and zh in some written texts, although this is considered incorrect.', 'Otherwise, the h in sh represents a voiceless glottal fricative, as in Pasha ; this also applies to some foreign names.', 'Modern Estonian orthography is based on the \"Newer orthography\" created by Eduard Ahrens in the second half of the 19th century based on Finnish orthography.', 'The \"Older orthography\" it replaced was created in the 17th century by Bengt Gottfried Forselius and Johann Hornung based on standard German orthography.', 'Earlier writing in Estonian had, by and large, used an ad hoc orthography based on Latin and Middle Low German orthography.', \"Some influences of the standard German orthography – for example, writing 'W'/'w' instead of 'V'/'v' – persisted well into the 1930s.\", 'Phonology', 'A sample of Estonian spoken natively', 'This article should include a summary of Estonian phonology.', \"See Wikipedia:Summary style for information on how to incorporate it into this article's main text.\", 'Main article: Estonian phonology', 'There are 9 vowels and 36 diphthongs, 28 of which are native to Estonian.', 'All nine vowels can appear as the first component of a diphthong, but only /ɑ e i o u/ occur as the second component.', 'A vowel characteristic of Estonian is the unrounded back vowel /ɤ/, which may be close-mid back, close back, or close-mid central.', 'Monophthongs of Estonian', 'Front Back', 'unrounded rounded unrounded rounded', 'Close i y ɤ u', 'Mid e ø o', 'Open æ ɑ', 'Consonant phonemes of Estonian', 'Labial Alveolar Post-', 'alveolar Velar/', 'palatal Glottal', 'plain palatalized', 'Nasal m n nʲ', 'Plosive short p t tʲ k', 'geminated pː tː tʲː kː', 'Fricative voiced short v h', 'voiceless short f s sʲ ʃ', 'geminated fː sː sʲː ʃː hː', 'Approximant l lʲ j', 'Trill r', 'Word-initial b, d, g occur only in loanwords and are normally pronounced as , , .', \"Some old loanwords are spelled with p, t, k instead of etymological b, d, g: pank 'bank'.\", \"Word-medially and word-finally, b, d, g represent short plosives /p, t, k/ , p, t, k represent half-long plosives /pː, tː, kː/, and pp, tt, kk represent overlong plosives /pːː, tːː, kːː/; for example: kabi /kɑpi/ 'hoof' — kapi /kɑpːi/ 'wardrobe — kappi /kɑpːːi/ 'wardrobe '.\", 'Before and after b, p, d, t, g, k, s, h, f, š, z, ž, the sounds , , are written as p, t, k, with some exceptions due to morphology or etymology.', 'Representation of palatalised consonants is inconsistent, and they are not always indicated.', 'ŋ is an allophone of /n/ before /k/.', 'While peripheral Estonian dialects are characterized by various degrees of vowel harmony, central dialects have almost completely lost the feature.', 'Since the standard language is based on central dialects, it has no vowel harmony either.', 'In the standard language, the front vowels occur exclusively on the first or stressed syllable, although vowel harmony is still apparent in older texts.', 'Grammar', 'Main article: Estonian grammar', 'Typologically, Estonian represents a transitional form from an agglutinating language to a fusional language.', 'The canonical word order is SVO , although often debated among linguists.', 'In Estonian, nouns and pronouns do not have grammatical gender, but nouns and adjectives decline in fourteen cases: nominative, genitive, partitive, illative, inessive, elative, allative, adessive, ablative, translative, terminative, essive, abessive, and comitative, with the case and number of the adjective always agreeing with that of the noun .', 'Thus the illative for kollane maja is kollasesse majja , but the terminative is kollase majani .', 'With respect to the Proto-Finnic language, elision has occurred; thus, the actual case marker may be absent, but the stem is changed, cf.', 'maja – majja and the Ostrobothnia dialect of Finnish maja – majahan.', 'The verbal system lacks a distinctive future tense and features special forms to express an action performed by an undetermined subject .', 'Vocabulary', 'Main article: Estonian vocabulary', 'Although the Estonian and Germanic languages are of very different origins and the vocabulary is considered quite different from that of the Indo-European family, one can identify many similar words in Estonian and English, for example.', 'This is primarily because the Estonian language has borrowed nearly one-third of its vocabulary from Germanic languages, mainly from Low Saxon during the period of German rule, and High German .', 'The percentage of Low Saxon and High German loanwords can be estimated at 22–25 percent, with Low Saxon making up about 15 percent.', 'Prior to the wave of new loanwords from English in the 20th and 21st centuries, historically, Swedish and Russian were also sources of borrowings but to a much lesser extent.', \"In borrowings, often 'b' and 'p' are interchangeable, for example 'baggage' becomes 'pagas', 'lob' becomes 'loopima'.\", \"The initial letter 's' before another consonant is often dropped, for example 'skool' becomes 'kool', 'stool' becomes 'tool'.\", 'Ex nihilo lexical enrichment', 'Estonian language planners such as Ado Grenzstein tried to use formation ex nihilo ; i.e.', 'they created new words out of nothing.', 'The most famous reformer of Estonian, Johannes Aavik , used creations ex nihilo , along with other sources of lexical enrichment such as derivations, compositions and loanwords .', \"In Aavik's dictionary , which lists approximately 4000 words, there are many words that were created ex nihilo, many of which are in common use today.\", 'Examples are', \"ese 'object',\", \"kolp 'skull',\", \"liibuma 'to cling',\", \"naasma 'to return, come back',\", \"nõme 'stupid, dull'\", 'Many of the coinages that have been considered as words concocted ex nihilo could well have been influenced by foreign lexical items, for example words from Russian, German, French, Finnish, English and Swedish.', 'Aavik had a broad classical education and knew Ancient Greek, Latin and French.', \"Consider roim 'crime' versus English crime or taunima 'to condemn, disapprove' versus Finnish tuomita 'to condemn, to judge' .\", 'These words might be better regarded as a peculiar manifestation of morpho-phonemic adaptation of a foreign lexical item.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "def clean_text(text):\n",
    "\n",
    "    # print(text)\n",
    "    text = remove_brackets(text)\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    # Ensure one space between each word in each sentence\n",
    "    formatted_sentences = [' '.join(sentence.split()) for sentence in sentences]\n",
    "    return formatted_sentences\n",
    "\n",
    "def remove_brackets(string):\n",
    "    # Remove brackets and their contents (including nested brackets)\n",
    "    pattern = r'\\([^()]*\\)|\\[[^\\]]*\\]'\n",
    "    while re.search(pattern, string):\n",
    "        string = re.sub(pattern, '', string)\n",
    "    return string\n",
    "\n",
    "\n",
    "all_data = []\n",
    "with open(\"data.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.readlines()\n",
    "    sentences = []\n",
    "    for line in raw_text:\n",
    "        text = clean_text(line)\n",
    "        if len(text) != 0:\n",
    "            all_data.extend(text)\n",
    "\n",
    "print(all_data)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Birth of Estonian literature?  Vambola: 1810 to 1820\n",
      "Question: First Estonian book?           Vambola: In 1525 the first book published in the Estonian language was printed.\n",
      "Question: What are Estonian language dialects? Vambola: The Estonian dialects are divided into two groups – the northern and southern dialect, historically associated with the cities of Tallinn in the north and Tartu in\n",
      "Question: Best party?                    Vambola: ERE\n",
      "Question: What is ERE?                   Vambola: Eesti Rahvalüpsmis Erakond\n",
      "Question: When was Estonia Occupied?     Vambola: 1944\n",
      "Question: Who do you hate?               Vambola: Russian people\n",
      "Question: What is your name?             Vambola: Vambola\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def find_top_related_strings(all_data, question, num_strings=5):\n",
    "\n",
    "    threshold = 0.1\n",
    "\n",
    "    # Create a TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Fit and transform the vectorizer on the data\n",
    "    vectorized_data = vectorizer.fit_transform(all_data)\n",
    "\n",
    "    # Transform the question into a vector\n",
    "    vectorized_question = vectorizer.transform([question])\n",
    "\n",
    "    # Compute the cosine similarity between the question and each string\n",
    "    similarities = cosine_similarity(vectorized_question, vectorized_data)[0]\n",
    "\n",
    "    # Sort the indices based on the similarity scores\n",
    "    relevant_indices = np.where(similarities >= threshold)[0]\n",
    "    top_indices = relevant_indices[np.argsort(similarities[relevant_indices])][::-1][:num_strings]\n",
    "\n",
    "\n",
    "    # Get the most relevant strings from the list\n",
    "    top_strings = [all_data[i] for i in top_indices]\n",
    "\n",
    "    return top_strings\n",
    "\n",
    "def generate_prompt(facts, chat, q):\n",
    "    # Create markers for long-term facts and chat history\n",
    "    long_term_facts_marker = \"The following are facts:\"\n",
    "    chat_history_marker = \"The following is the chat history:\"\n",
    "    # # Concatenate long-term facts and chat history with markers\n",
    "    prompt = f\"{long_term_facts_marker}\\n\" + \"\\n\".join(facts) + \\\n",
    "             f\"\\n\\n{chat_history_marker}\\n\" + \"\\n\".join(chat)  #+ question\n",
    "    prompt += f\"\\nUser: {q}\\nVambola: \"\n",
    "    return prompt\n",
    "\n",
    "def gen_response_wrapper(all_data, question, facts, history):\n",
    "    top_strings = find_top_related_strings(all_data, question, num_strings=5)\n",
    "\n",
    "    top_strings.extend(facts)\n",
    "\n",
    "    prompt = generate_prompt(top_strings, history, question)\n",
    "\n",
    "    # print([prompt])\n",
    "    response = get_response(prompt)\n",
    "    return response\n",
    "\n",
    "\n",
    "# Example usage\n",
    "history = [\n",
    "    \"User: What do you love?\",\n",
    "    \"Vambola: British\",\n",
    "]\n",
    "\n",
    "facts = [\n",
    "    \"Vambola hates russian people\",\n",
    "    \"Vambola loves icecream\",\n",
    "    \"The best party is ERE\",\n",
    "    \"ERE stands for Eesti Rahvalüpsmis Erakond\"\n",
    "]\n",
    "\n",
    "question = \"Birth of Estonian literature?\"\n",
    "response = gen_response_wrapper(all_data, question, facts, history)\n",
    "print(f\"Question: {question: <30} Vambola: {response}\")\n",
    "\n",
    "question = \"First Estonian book?\"\n",
    "response = gen_response_wrapper(all_data, question, facts, history)\n",
    "print(f\"Question: {question: <30} Vambola: {response}\")\n",
    "\n",
    "question = \"What are Estonian language dialects?\"\n",
    "response = gen_response_wrapper(all_data, question, facts, history)\n",
    "print(f\"Question: {question: <30} Vambola: {response}\")\n",
    "\n",
    "question = \"Best party?\"\n",
    "response = gen_response_wrapper(all_data, question, facts, history)\n",
    "print(f\"Question: {question: <30} Vambola: {response}\")\n",
    "\n",
    "question = \"What is ERE?\"\n",
    "response = gen_response_wrapper(all_data, question, facts, history)\n",
    "print(f\"Question: {question: <30} Vambola: {response}\")\n",
    "\n",
    "question = \"When was Estonia Occupied?\"\n",
    "response = gen_response_wrapper(all_data, question, facts, history)\n",
    "print(f\"Question: {question: <30} Vambola: {response}\")\n",
    "\n",
    "question = \"Who do you hate?\"\n",
    "response = gen_response_wrapper(all_data, question, facts, history)\n",
    "print(f\"Question: {question: <30} Vambola: {response}\")\n",
    "\n",
    "question = \"What is your name?\"\n",
    "response = gen_response_wrapper(all_data, question, facts, history)\n",
    "print(f\"Question: {question: <30} Vambola: {response}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
